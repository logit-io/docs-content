---
title: Getting started with Grafana
metaTitle: Learn about Viewing Metrics in Grafana
description: Read Logit.io's Getting Started with Grafana article and learn about viewing metrics in Grafana
stackTypes: metrics
---

# Getting started with Grafana

In this guide we are going to explain what Grafana is, how to view your data in Grafana and how to create a dashboard. We will go through a 
step-by-step example of viewing an individual metric in Grafana and then creating a simple dashboard.

## What is Grafana?

Grafana is an open-source analytics and visualization tool that allows you to monitor, query, and visualize data from a wide range of sources in real time. 
It's especially popular in system monitoring, observability, and DevOps because it enables users to create highly customizable, interactive dashboards 
that consolidate complex metrics into clear, actionable insights. By supporting multiple data sources like VictoriaMetrics, Prometheus, Elasticsearch, 
and many more, Grafana serves as a central hub for monitoring infrastructure and applications. Its flexibility, combined with features like 
alerting and annotation, makes it invaluable for identifying trends, diagnosing issues, and optimizing performance in a visually intuitive way. 

Whether you're tracking system health or analyzing user behavior, Grafana is a powerful tool to turn raw data into meaningful visuals.

## Viewing your data in Grafana

Now we're going to show you how to view your data in Grafana with a very simple example.
These are the steps we will follow:
- Install Telegraf and configure it to send metrics to Logit.io.
- Send a simple metric to Logit.io.
- View the metric in Grafana.

### Install Telegraf

This integration allows you to configure a Telegraf agent to send your metrics, in multiple formats, to Logit.io.

Choose the installation method for your operating system:

<Tabs items={["Windows (Powershell)", "Ubuntu & Debian", "macOS", "Red Hat & centOS", "Linux binaries (64-bit)"]}>
  <Tab>
    When you paste the command below into Powershell it will download the Telegraf zip file. 
    Once that is complete, press Enter again and the zip file will be extracted into `C:\Program Files\InfluxData\telegraf\telegraf-1.34.1`.

    ```cmd copy
    wget https://dl.influxdata.com/telegraf/releases/telegraf-1.34.1_windows_amd64.zip -UseBasicParsing -OutFile telegraf-1.34.1_windows_amd64.zip 
    Expand-Archive .\telegraf-1.34.1_windows_amd64.zip -DestinationPath 'C:\Program Files\InfluxData\telegraf'
    ```
  </Tab>
  <Tab>
    Debian and Ubuntu users can install the latest stable version of Telegraf using the apt-get package manager.
    Ubuntu 20.04 LTS and newer: 

    ```cmd copy
    curl --silent --location -O \
    https://repos.influxdata.com/influxdata-archive.key \
    && echo "943666881a1b8d9b849b74caebf02d3465d6beb716510d86a39f6c8e8dac7515  influxdata-archive.key" \
    | sha256sum -c - && cat influxdata-archive.key \
    | gpg --dearmor \
    | sudo tee /etc/apt/trusted.gpg.d/influxdata-archive.gpg > /dev/null \
    && echo 'deb [signed-by=/etc/apt/trusted.gpg.d/influxdata-archive.gpg] https://repos.influxdata.com/debian stable main' \
    | sudo tee /etc/apt/sources.list.d/influxdata.list
    sudo apt-get update && sudo apt-get install telegraf
    ```
  </Tab>
  <Tab>
    ```cmd copy
    brew update
    brew install telegraf
    ```
  </Tab>
  <Tab>
    ```cmd copy
    cat <<EOF | sudo tee /etc/yum.repos.d/influxdata.repo
    [influxdata]
    name = InfluxData Repository - Stable
    baseurl = https://repos.influxdata.com/stable/$basearch/main
    enabled = 1
    gpgcheck = 1
    gpgkey = file:///etc/pki/rpm-gpg/RPM-GPG-KEY-influxdata
    EOF
    ```
    Then enter the following command to install Telegraf:
  
    ```cmd copy
    sudo yum install telegraf
    ```
  </Tab>
  <Tab>
    ```cmd copy
    wget https://dl.influxdata.com/telegraf/releases/telegraf-1.34.1_linux_amd64.tar.gz
    tar xf telegraf-1.34.1_linux_amd64.tar.gz
    ```
  </Tab>
</Tabs>

### Configure Telegraf

The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `/etc/telegraf/telegraf.conf` from the previous step.
<Tabs items={["Windows (Powershell)", "Ubuntu & Debian", "macOS", "Red Hat & centOS", "Linux binaries (64-bit)"]}>
  <Tab>
    We are going to use the `win_perf_counters` input plugin to scrape the CPU usage metric from your Windows host.
  
    ```toml copy
    [[inputs.win_perf_counters]]
      [[inputs.win_perf_counters.object]]
        ObjectName = "Processor"
        Instances = ["_Total"]
        Counters = [
          "% Processor Time",
        ]
        Measurement = "win_cpu"
        IncludeTotal = true
    
        [[outputs.http]]
        url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
        data_format = "prometheusremotewrite"
    
        [outputs.http.headers]
          Content-Type = "application/x-protobuf"
          Content-Encoding = "snappy"
    ```
  </Tab>
  <Tab>
    We are going to use the `inputs.cpu` input plugin to scrape the CPU usage metric from your host.
  
    ```toml copy
    [[inputs.cpu]]
    ## Whether to report per-cpu stats or not
    percpu = false
    ## Whether to report total system cpu stats or not
    totalcpu = true
    ## If true, collect raw CPU time metrics
    collect_cpu_time = false
    ## If true, compute and report the sum of all non-idle CPU states
    ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
    report_active = false
    ## If true and the info is available then add core_id and physical_id tags
    core_tags = false
    ```
  </Tab>
  <Tab>
    We are going to use the `inputs.cpu` input plugin to scrape the CPU usage metric from your host.

    ```toml copy
    [[inputs.cpu]]
    ## Whether to report per-cpu stats or not
    percpu = false
    ## Whether to report total system cpu stats or not
    totalcpu = true
    ## If true, collect raw CPU time metrics
    collect_cpu_time = false
    ## If true, compute and report the sum of all non-idle CPU states
    ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
    report_active = false
    ## If true and the info is available then add core_id and physical_id tags
    core_tags = false
    ```
  </Tab>
  <Tab>
    We are going to use the `inputs.cpu` input plugin to scrape the CPU usage metric from your host.

    ```toml copy
    [[inputs.cpu]]
    ## Whether to report per-cpu stats or not
    percpu = false
    ## Whether to report total system cpu stats or not
    totalcpu = true
    ## If true, collect raw CPU time metrics
    collect_cpu_time = false
    ## If true, compute and report the sum of all non-idle CPU states
    ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
    report_active = false
    ## If true and the info is available then add core_id and physical_id tags
    core_tags = false
    ```
  </Tab>
  <Tab>
    We are going to use the `inputs.cpu` input plugin to scrape the CPU usage metric from your host.
  
    ```toml copy
    [[inputs.cpu]]
    ## Whether to report per-cpu stats or not
    percpu = false
    ## Whether to report total system cpu stats or not
    totalcpu = true
    ## If true, collect raw CPU time metrics
    collect_cpu_time = false
    ## If true, compute and report the sum of all non-idle CPU states
    ## NOTE: The resulting 'time_active' field INCLUDES 'iowait'!
    report_active = false
    ## If true and the info is available then add core_id and physical_id tags
    core_tags = false
    ```
  </Tab>
</Tabs>


## Grafana Dashboards

Dashboards in Grafana are dynamic, interactive visual interfaces that provide a consolidated view of data from various sources. 
They are highly customizable, allowing users to arrange panels to display metrics in formats such as graphs, gauges, heatmaps, and tables. 
Dashboards are essential for monitoring system health, tracking performance trends, and identifying anomalies across infrastructure or applications. 
With features like real-time updates, templating, and filters, they empower users to make informed decisions quickly and efficiently. 
Whether you're a developer troubleshooting an issue or an operations team optimizing resources, dashboards serve as a single-pane-of-glass 
view that simplifies complex data into actionable insights. Let me know if you'd like to dive into specific dashboard features!





You can find instructions X [here](../integrations/windows#logs)

