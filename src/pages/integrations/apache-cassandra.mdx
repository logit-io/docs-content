---
title: Apache Cassandra
metaTitle: Integrate and Configure Telegraf to send Apache Cassandra Metrics
subTitle: Ship your Apache Cassandra Metrics via Telegraf to your Logit.io Stack
logo: cassandra
color: "#4d4d4d"
description: Use our example to configure Telegraf to ship Apache Cassandra metrics to Logit.io.
stackTypes: metrics
sslPortType: beats-ssl
tags: Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation, Apache Cassandra, Prometheus, Database, NoSQL
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Metrics

  Configure Telegraf to ship Apache Cassandra metrics to your Logit.io stacks.

  ### Install Integration
  <InstallIntegration/>
  ### Install Telegraf

  <InstallTelegraf />

  ### Configure Telegraf

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `telegraf.conf` from the previous step. Update the 'servers' field with the appropriate values.

  ```toml copy filename="telegraf.conf" showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  ### Read Cassandra metrics through Jolokia
  [[inputs.cassandra]]
    context = "/jolokia/read"
    ## List of cassandra servers exposing jolokia read service
    servers = ["myuser:mypassword@10.10.10.1:8778","10.10.10.2:8778",":8778"]
    ## List of metrics collected on above servers
    ## Each metric consists of a jmx path.
    ## This will collect all heap memory usage metrics from the jvm and
    ## ReadLatency metrics for all keyspaces and tables.
    ## "type=Table" in the query works with Cassandra3.0. Older versions might
    ## need to use "type=ColumnFamily"
    metrics  = [
      "/java.lang:type=Memory/HeapMemoryUsage",
      "/org.apache.cassandra.metrics:type=Table,keyspace=*,scope=*,name=ReadLatency"
    ]

  ### System metrics
  [[inputs.disk]]
  [[inputs.net]]
  [[inputs.mem]]
  [[inputs.system]]
  [[inputs.cpu]]
    percpu = false
    totalcpu = true
    collect_cpu_time = true
    report_active = true

  ### Output
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"

    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```

  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [Apache Cassandra](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/cassandra)
  </Callout>

  ### Start Telegraf

  <StartTelegraf />

  ### Launch Grafana to View Your Data

  <LaunchVisualizer type="metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### Telegraf Apache Cassandra Overview

In order to efficiently monitor and analyze Apache Cassandra metrics in a distributed environment, it's essential to utilize a trustworthy and 
effective metrics management solution. Telegraf, an open-source metrics collection agent, fits this role perfectly, capable of extracting Apache 
Cassandra metrics from a multitude of sources, including operational Cassandra clusters, databases, and other relevant applications.

Telegraf provides an extensive range of input plugins, allowing users to gather metrics from diverse sources such as CPU usage, memory 
consumption, network activity, and more. For storing and querying these collected metrics, organizations can turn to Prometheus, an open-source 
monitoring and alerting system noted for its flexible querying language and powerful graphical data visualization capabilities.

To ship Apache Cassandra metrics from Telegraf to Prometheus, organizations need to configure Telegraf to output metrics in the Prometheus 
format, and then arrange for Prometheus to scrape these metrics from the Telegraf server. This process involves configuring Telegraf to 
accumulate Apache Cassandra metrics, rendering them in the Prometheus format, setting up Prometheus to retrieve these metrics from the Telegraf 
server, and then visually interpreting the data using Prometheus's dynamic querying and graphical visualization tools.

Once the metrics are successfully incorporated into Prometheus, further analysis and visualization can be conducted using Grafana. Grafana is an 
open-source platform renowned for its monitoring and observability capabilities, and is fully compatible with Prometheus. It enables users to 
construct dynamic and interactive dashboards for a deeper understanding of the metrics data, offering a more comprehensive view of performance 
trends and potential issues.

If you need any further assistance with shipping your log data to Logit.io we're here to help you get started. Feel free to get in contact with 
our support team by sending us a message via <IntercomButton text="live chat" /> & we'll be happy to assist.


