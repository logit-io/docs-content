---
title: Google Kubernetes Engine Metrics
metaTitle: Configure Telegraf to Send Google Kubernetes Engine Metrics
subTitle: Ship Google Kubernetes Engine Metrics to Logstash
logo: googlecloud
color: "#3a64ad"
description: Send your Google Kubernetes Engine metrics to logit.io via logstash using the instructions below and begin searching your data
stackTypes: metrics
sslPortType: beats-ssl
tags: Metrics, Google, GKE, Container, Kubernetes, Google Kubernetes Engine, Google Cloud, Cloud Metrics, Gke
---

Metricbeat is an open source shipping agent that lets you ship Google 
Kubernetes Engine (GKE) Metrics to one or more destinations, including Logstash.

<Steps>
  ## Metrics
  ### Install Integration
  <InstallIntegration/>
  ### Configure GKE

  Open [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/) in Google Cloud, choose to create a cluster, give it a suitable name, and choose a region for your cluster.

  ![Create a cluster](@/images/integrations/gke/step-one.png)

  ### Connecting to the cluster

  Once the cluster is created you will see a similar screen to the below. Go ahead and hit Connect.

  ![Connect to cluster](@/images/integrations/gke/step-two.png)      

  You'll have two options, we're going to choose to Run in Cloud Shell.

  ![Run in Cloud Shell](@/images/integrations/gke/step-three.png)

  This will open a terminal window in your browser. (It can take a few seconds to load)

  ![Wait for terminal to load](@/images/integrations/gke/step-four.png)

  ### Setting up the terminal

  You'll have to run the initial command that comes pre-populated in the terminal to authenticate. 
  Wait a few seconds for this to process and then you're going to download the following 
  Logit.io Metricbeat Kubernetes deployment manifest.

  To download the Logit.io deployment manifest for GKE, in the GKE terminal run:

  ```cmd copy
  curl -L -O cdn.logit.io/metricbeat-kubernetes-7.9.3.yaml
  ```

  ### Deploy Metricbeat

  Now you have the manifest we need to add your Stack Logstash endpoint details. 
  Open the file in terminal editor using vim or nano command. Alternatively you can choose 
  Open Editor from the console toolbar to make your changes.

  ```cmd copy
  vi metricbeat-kubernetes-7.9.3.yaml
  ```
  
  or

  ```cmd copy
  nano metricbeat-kubernetes-7.9.3.yaml
  ```

  Update the following lines in the yaml with your Stack Logstash endpoint and Beats-SSL port.
  
  <Callout type="info">
    Note: The code snippet occurs two times in the yaml file and needs updating in both.
  </Callout>

  ```cmd copy
  env:
  - name: LOGSTASH_HOST
    value: "guid-ls.logit.io"
  - name: BEATS_PORT
    value: "00000"
  ```

  After updating the code should look as below.

  ```cmd copy
  env:
  - name: LOGSTASH_HOST
    value: ["@logstash.host"]
  - name: BEATS_PORT
    value: ["@logstash.sslPort"]
  ```

  Exit and save the file.

  ### Apply your updates

  Now we're going to apply the file to the cluster.

  ```cmd copy
  kubectl apply -f metricbeat-kubernetes-7.9.3.yaml
  ```

  You should see output similar to that below confirming that the file has been created.

  ![Output of file successfully created](@/images/integrations/gke/step-five.png)

  <Callout type="info">
    If you need to apply further updates after running the apply command you may need to remove the yaml file, make your changes and then apply again.
  </Callout>

  ### Confirm Deployment

  Confirm your pod has deployed, you should see output similar to that below.

  ```cmd copy
  kubectl --namespace=kube-system get ds/metricbeat
  ```
  ![kubectl pod deployment](@/images/integrations/gke/step-seven.png)

  Browse to Kibana and you should see Metrics arriving in your Stack.

  In the GKE console you can view the log file to confirm that Metrics are being sent to your Logit.io Stack 
  using the following command.

  ```cmd copy
  kubectl logs ["podname"] --namespace=kube-system
  ```

  Metricbeat requires kube-state-metrics to be deployed and running to gather the cluster metrics. 
  Follow the [Kubernetes deployment](https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment) docs to get this set-up.

  ### View your metrics
  <LaunchStack stackType="metrics" source="gke" utmMedium="metrics" utmCampaign="gke" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />
</Steps>

## GKE Kibana dashboards

Kibana includes some pre-built dashboards for Google Kubernetes Engine (GKE). To view your dashboards for 
any of your Logit.io Stacks, launch Kibana, choose Dashboards and filter for Kubernetes.

![Prebuilt Kibana dashboard](@/images/integrations/gke/gke-dashboard-one.png)

![Prebuilt Kibana dashboard](@/images/integrations/gke/gke-dashboard-two.png)

## GKE Logging Overview

Google Kubernetes Engine (often shortened to GKE) is a managed service for running 
[Kubernetes](/integrations/log-management/containerisation/kubernetes) 
that bypasses the need to install and operate the clusters typically required to run the popular container management tool.

It is often used for managing containers due to container's increased proficiency for meeting the 
performance and scalability requirements demanded when new enterprise level applications are 
being created and subsequently require testing and maintaining.

Google officially open-sourced Kubernetes in 2014 and since then it quickly became one of the most 
popular container management tools. By offering this as a managed service, Google provides an easy 
route for users that don't wish to maintain K8s but still want the benefits that lead to lowering 
of their cloud computing costs.

As part of this service GKE also provides users with a sandbox that gives an additional layer of 
workload security, private clusters can also be restricted to a private endpoint which operates 
as a benefit for organisations that require enhanced security.

It is important that when using Google Kubernetes Engine that you make sure that cloud logging 
is not disabled. When this functionality is disabled it can make troubleshooting incidents 
extremely difficult and if a pod is removed it may make these logs nearly impossible to recover 
for effective root cause analysis to be undertaken.

GKE collects logs for all of the following areas; cluster audit data, worker nodes, application files and system logs.
As important as making sure GKE cloud logging is enabled it is also vital that your 
organisation also makes allowances for long term storage of your Google Kubernetes Engines 
within a centralised logging platform.

Logit.io provides centralised log management that brings together all logs from managed services, 
K8s, applications, servers and programming languages in a single affordable platform to give 
your engineers a unified view across the entire health of your operating environment.

If you require any further help with migrating your Google Kubernetes Engine log files 
using Logstash we're here to help. Feel free to get in contact with our support team via <IntercomButton text="live chat" /> & we'll be happy to assist.