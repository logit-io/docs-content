---
title: Ceph Metrics
metaTitle: Learn How to Integrate and Configure Telegraf to Send Ceph Metrics
subTitle: Ship your Ceph Metrics via Telegraf to your Logit.io Stack
color: "#4d4d4d"
description: Use our example to configure Telegraf to ship Ceph metrics to your Logit.io stacks. Configure Telegraf to send Ceph metrics to Logstash or Elastic.
stackTypes: metrics
sslPortType: beats-ssl
tags: Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation, Prometheus, Ceph, Distributed Storage
---

TODO: Add description

<Steps>
  ## Metrics

  Configure Telegraf to ship Ceph metrics to your Logit.io stacks via Logstash.
  
  ### Install Integration
  <InstallIntegration/>

  ### Install Telegraf

  <InstallTelegraf />

  ### Configure the Telegraf input plugin

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `/etc/telegraf/telegraf.conf` from the previous step.

  ```toml copy
  # Collects performance metrics from the MON, OSD, MDS and RGW nodes
  # in a Ceph storage cluster.
  [[inputs.ceph]]
    ## This is the recommended interval to poll. Too frequent and you
    ## will lose data points due to timeouts during rebalancing and recovery
    interval = '1m'

    ## All configuration values are optional, defaults are shown below

    ## location of ceph binary
    ceph_binary = "/usr/bin/ceph"

    ## directory in which to look for socket files
    socket_dir = "/var/run/ceph"

    ## prefix of MON and OSD socket files, used to determine socket type
    mon_prefix = "ceph-mon"
    osd_prefix = "ceph-osd"
    mds_prefix = "ceph-mds"
    rgw_prefix = "ceph-client"

    ## suffix used to identify socket files
    socket_suffix = "asok"

    ## Ceph user to authenticate as, ceph will search for the corresponding
    ## keyring e.g. client.admin.keyring in /etc/ceph, or the explicit path
    ## defined in the client section of ceph.conf for example:
    ##
    ##     [client.telegraf]
    ##         keyring = /etc/ceph/client.telegraf.keyring
    ##
    ## Consult the ceph documentation for more detail on keyring generation.
    ceph_user = "client.admin"

    ## Ceph configuration to use to locate the cluster
    ceph_config = "/etc/ceph/ceph.conf"

    ## Whether to gather statistics via the admin socket
    gather_admin_socket_stats = true

    ## Whether to gather statistics via ceph commands, requires ceph_user
    ## and ceph_config to be specified
    gather_cluster_stats = false
  ```

  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [Ceph](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ceph)
  </Callout>

  ### Configure The Output plugin

  <TelegrafOutputPlugin />

  ### Start Telegraf

  <StartTelegraf />

  ### View your metrics
  <LaunchStack source="Ceph_Metrics_via_Telegraf" utmMedium="metrics" utmCampaign="telegraf-Ceph-metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### Telegraf Ceph Overview

To efficiently monitor and analyze Ceph metrics in a distributed environment, it's imperative to have a dependable and proficient metrics 
management solution. Telegraf, an open-source metrics collection agent, is perfectly suited for this task, capable of gathering Ceph metrics 
from a multitude of sources, including operational Ceph clusters, databases, and other relevant applications.

Telegraf offers an extensive assortment of input plugins, enabling users to collect metrics from various sources such as CPU usage, memory 
consumption, network activity, and more. For storing and analyzing these harvested metrics, organizations can make use of Prometheus, an 
open-source monitoring and alerting system celebrated for its flexible querying language and robust graphical data visualization capabilities.

To ship Ceph metrics from Telegraf to Prometheus, organizations need to configure Telegraf to output metrics in the Prometheus format, and then 
set up Prometheus to scrape these metrics from the Telegraf server. This procedure involves setting up Telegraf to collect Ceph metrics, 
outputting them in the Prometheus format, arranging Prometheus to retrieve these metrics from the Telegraf server, and then visually interpreting 
the data using Prometheus's dynamic querying and graphical visualization tools.

Once the metrics are successfully transferred into Prometheus, further analysis and visualization can be conducted using Grafana. Grafana is an 
open-source platform well-known for its monitoring and observability capabilities, and is fully compatible with Prometheus. It allows users to 
create dynamic, interactive dashboards for a deeper understanding of the metrics data, providing a comprehensive view of performance trends and 
potential issues.

If you need any further assistance with shipping your log data to Logit.io we're here to help you get started. Feel free to get in contact with 
our support team by sending us a message via <IntercomButton text="live chat" /> & we'll be happy to assist.