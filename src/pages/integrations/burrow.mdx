---
title: Burrow
metaTitle: Learn How to Integrate and Configure Telegraf to Send Burrow Metrics
subTitle: Ship your Burrow Metrics via Telegraf to your Logit.io Stack
logo: kafka
color: "#4d4d4d"
description: Use our example to configure Telegraf to ship Burrow metrics to your Logit.io stacks.
stackTypes: metrics
sslPortType: beats-ssl
tags: Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation, Burrow, Prometheus, Kafka Consumer Lag
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Metrics

  Configure Telegraf to ship Burrow metrics to your Logit.io stacks.
  
  ### Install Integration
  <InstallIntegration/>

  ### Install Telegraf

  <InstallTelegraf />

  ### Configure Telegraf

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `telegraf.conf` from the previous step.

  ```toml copy filename="telegraf.conf" showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  ### Collect Kafka topics and consumers status from Burrow HTTP API.
  [[inputs.burrow]]
    ## Burrow API endpoints in format "schema://host:port".
    ## Default is "http://localhost:8000".
    servers = ["http://localhost:8000"]

    ## Override Burrow API prefix.
    ## Useful when Burrow is behind reverse-proxy.
    # api_prefix = "/v3/kafka"

    ## Maximum time to receive response.
    # response_timeout = "5s"

    ## Limit per-server concurrent connections.
    ## Useful in case of large number of topics or consumer groups.
    # concurrent_connections = 20

    ## Filter clusters, default is no filtering.
    ## Values can be specified as glob patterns.
    # clusters_include = []
    # clusters_exclude = []

    ## Filter consumer groups, default is no filtering.
    ## Values can be specified as glob patterns.
    # groups_include = []
    # groups_exclude = []

    ## Filter topics, default is no filtering.
    ## Values can be specified as glob patterns.
    # topics_include = []
    # topics_exclude = []

    ## Credentials for basic HTTP authentication.
    # username = ""
    # password = ""

    ## Optional SSL config
    # ssl_ca = "/etc/telegraf/ca.pem"
    # ssl_cert = "/etc/telegraf/cert.pem"
    # ssl_key = "/etc/telegraf/key.pem"
    # insecure_skip_verify = false

  ### System metrics
  [[inputs.disk]]
  [[inputs.net]]
  [[inputs.mem]]
  [[inputs.system]]
  [[inputs.cpu]]
    percpu = false
    totalcpu = true
    collect_cpu_time = true
    report_active = true

  ### Output
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"

    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```

  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [Burrow](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/burrow)
  </Callout>

  ### Start Telegraf

  <StartTelegraf />

  ### Launch Grafana to View Your Data

  <LaunchVisualizer type="metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### Telegraf Burrow Overview

To efficiently monitor and analyze Burrow metrics in a distributed environment, a solid metrics management solution is key. Telegraf, an 
open-source server agent, fits this role perfectly. It can gather Burrow metrics from various sources, including operational Burrow instances, 
databases, and other relevant applications.

Telegraf offers a comprehensive set of input plugins that enable users to collect diverse metrics, such as CPU usage, memory utilization, network 
traffic, and more, which are vital for understanding Burrow's performance. To store and examine these metrics, organizations can use Prometheus, 
an open-source monitoring and alerting toolkit known for its flexible querying language and robust data visualization capabilities.

To transport Burrow metrics from Telegraf to Prometheus, organizations need to configure Telegraf to output metrics in the Prometheus format and 
then set up Prometheus to scrape these metrics from the Telegraf server. This process involves setting up Telegraf to collect Burrow metrics, 
outputting them in the Prometheus format, configuring Prometheus to retrieve these metrics from the Telegraf server, and then visually interpreting 
the data using Prometheus's dynamic querying and graphical visualization tools.

Once the metrics are successfully integrated into Prometheus, further analysis and visualization can be carried out using Grafana. Grafana, a 
leading open-source platform recognized for its monitoring and observability features, is fully compatible with Prometheus. It allows users to 
create dynamic, interactive dashboards for a deeper dive into the metrics data, offering a comprehensive understanding of performance trends and 
potential issues within the Burrow system.

If you need any further assistance with shipping your log data to Logit.io we're here to help you get started. Feel free to get in contact with 
our support team by sending us a message via <IntercomButton text="live chat" /> & we'll be happy to assist.