---
title: MySQL
metaTitle: Learn How to Integrate and Configure MySQL to Send Logs
pageTitle: MySQL Logs
subTitle: Ship logs from MySQL to Logstash
logo: mysql
color: "#00758f"
description: Use Filebeat to send MySQL slow query and error logs to your ELK stacks. Configure Filebeat to send MySQL logs to Logstash or Elasticsearch. 
stackTypes: logs, metrics
sslPortType: beats-ssl
tags: Logs, Metrics, Database, DB, MySQL, RDBMS, Mysql, Telegraf, Telemetry, OpenTelemetry, Health, Instrumentation
dashboardIds: mysql
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Logs

  Configure Filebeat to ship logs from MySQL to Logstash and Elasticsearch.

  ### Install Integration
  <InstallIntegration/>
  ### Install Filebeat

  <InstallFilebeat />

  ### Enable the MySQL module

  <Tabs items={["Windows", "Linux", "macOS", "DEB", "RPM"]}>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the mysql module:

      ```cmd copy
      .\filebeat.exe modules list
      .\filebeat.exe modules enable mysql
      ```
      The default configured paths for MySQL logs are as follows:
              
      `c:\programdata\MySQL\MySQL Server*\error.log*`
      
      `c:\programdata\MySQL\MySQL Server*\mysql-slow.log*`

      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the mysql.yml module file:

      ```yml copy
      # Module: mysql
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-mysql.html

      - module: mysql
        # Error logs
        error:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:

        # Slow logs
        slowlog:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the mysql module:

      ```cmd copy
      sudo filebeat modules list
      sudo filebeat modules enable mysql
      ```

      The default configured paths for MySQL logs are as follows:

      `/var/log/mysql/mysql.log`
      
      `/var/log/mysql/mysql-slow.log`

      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the mysql.yml module file:

      ```yml copy
      # Module: mysql
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-mysql.html

      - module: mysql
        # Error logs
        error:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:

        # Slow logs
        slowlog:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the mysql module:

      ```cmd copy
      ./filebeat modules list
      ./filebeat modules enable mysql
      ```
      
      The default configured paths for MySQL logs are as follows:

      `/var/log/mysql/mysql.log`
      
      `/var/log/mysql/mysql-slow.log`

      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the mysql.yml module file:

      ```yml copy
      # Module: mysql
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-mysql.html

      - module: mysql
        # Error logs
        error:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:

        # Slow logs
        slowlog:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the mysql module:

      ```cmd copy
      sudo filebeat modules list
      sudo filebeat modules enable mysql
      ```

      The default configured paths for MySQL logs are as follows:

      `/var/log/mysql/mysql.log`
      
      `/var/log/mysql/mysql-slow.log`

      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the mysql.yml module file:

      ```yml copy
      # Module: mysql
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-mysql.html

      - module: mysql
        # Error logs
        error:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:

        # Slow logs
        slowlog:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the mysql module:

      ```cmd copy
      sudo filebeat modules list
      sudo filebeat modules enable mysql
      ```
      
      The default configured paths for MySQL logs are as follows:

      `/var/log/mysql/mysql.log`
      
      `/var/log/mysql/mysql-slow.log`
      
      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.
      
      Copy the snippet below and replace the contents of the mysql.yml module file:

      ```yml copy
      # Module: mysql
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-mysql.html

      - module: mysql
        # Error logs
        error:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:

        # Slow logs
        slowlog:
          enabled: true

        # Set custom paths for the log files. If left empty,
        # Filebeat will choose the paths depending on your OS.
        #var.paths:
      ```
    </Tab>
  </Tabs>

  ### Update Your Configuration File

  <UpdateFilebeatConfigFile />

  ### Validate configuration

  <ValidateBeat beatname="filebeat" />
  
  ### Start filebeat

  <StartFilebeat />

  ### Check Logit.io for your logs
  <LaunchStack utmMedium="logs" utmCampaign="mysql" source="mysql" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />
</Steps>

<Steps>
  ## Metrics

  Configure Telegraf to ship MySQL Server metrics to your Logit.io stacks via Logstash.
  
  ### Install Integration
  <InstallIntegration/>
  ### Install Telegraf

  <InstallTelegraf />

  ### Configure Telegraf

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `telegraf.conf` from the previous step.

  ```toml copy showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  ### Read metrics from one or many mysql servers
  [[inputs.mysql]]
    ## specify servers via a url matching:
    ##  [username[:password]@][protocol[(address)]]/[?tls=[true|false|skip-verify|custom]]
    ##  see https://github.com/go-sql-driver/mysql#dsn-data-source-name
    ##  e.g.
    ##    servers = ["user:passwd@tcp(127.0.0.1:3306)/?tls=false"]
    ##    servers = ["user@tcp(127.0.0.1:3306)/?tls=false"]
    #
    ## If no servers are specified, then localhost is used as the host.
    servers = ["tcp(127.0.0.1:3306)/"]

    ## Selects the metric output format.
    ##
    ## This option exists to maintain backwards compatibility, if you have
    ## existing metrics do not set or change this value until you are ready to
    ## migrate to the new format.
    ##
    ## If you do not have existing metrics from this plugin set to the latest
    ## version.
    ##
    ## Telegraf >=1.6: metric_version = 2
    ##           <1.6: metric_version = 1 (or unset)
    metric_version = 2

    ## if the list is empty, then metrics are gathered from all database tables
    # table_schema_databases = []

    ## gather metrics from INFORMATION_SCHEMA.TABLES for databases provided
    ## in the list above
      gather_table_schema = true

    ## gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST
      gather_process_list = true

    ## gather user statistics from INFORMATION_SCHEMA.USER_STATISTICS
      gather_user_statistics = true

    ## gather auto_increment columns and max values from information schema
      gather_info_schema_auto_inc = true

    ## gather metrics from INFORMATION_SCHEMA.INNODB_METRICS
      gather_innodb_metrics = true

    ## gather metrics from all channels from SHOW SLAVE STATUS command output
    # gather_all_slave_channels = false

    ## gather metrics from SHOW SLAVE STATUS command output
      gather_slave_status = true

    ## use SHOW ALL SLAVES STATUS command output for MariaDB
    # mariadb_dialect = false

    ## gather metrics from SHOW BINARY LOGS command output
      gather_binary_logs = true

    ## gather metrics from SHOW GLOBAL VARIABLES command output
      gather_global_variables = true

    ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE
      gather_table_io_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS
      gather_table_lock_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE
      gather_index_io_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS
      gather_event_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME
      gather_file_events_stats = true

    ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST
    # gather_perf_events_statements = false
    #
    ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_ACCOUNT_BY_EVENT_NAME
      gather_perf_sum_per_acc_per_event = true
    #
    ## list of events to be gathered for gather_perf_sum_per_acc_per_event
    ## in case of empty list all events will be gathered
    # perf_summary_events = []

    ## the limits for metrics form perf_events_statements
    # perf_events_statements_digest_text_limit = 120
    # perf_events_statements_limit = 250
    # perf_events_statements_time_limit = 86400

    ## Some queries we may want to run less often (such as SHOW GLOBAL VARIABLES)
    ##   example: interval_slow = "30m"
    # interval_slow = ""

    ## Optional TLS Config (used if tls=custom parameter specified in server uri)
    # tls_ca = "/etc/telegraf/ca.pem"
    # tls_cert = "/etc/telegraf/cert.pem"
    # tls_key = "/etc/telegraf/key.pem"
    ## Use TLS but skip chain & host verification
    # insecure_skip_verify = false

  ### System metrics
  [[inputs.disk]]
  [[inputs.net]]
  [[inputs.mem]]
  [[inputs.system]]
  [[inputs.cpu]]
    percpu = false
    totalcpu = true
    collect_cpu_time = true
    report_active = true

  ### Output
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"

    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```
  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [MySQL](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mysql)
  </Callout>

  ### Start Telegraf

  <StartTelegraf />

  ### View your metrics
  <LaunchStack source="MySQL_Server_Metrics_via_Telegraf" utmMedium="metrics" utmCampaign="telegraf-MySQL-metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### MySQL Dashboard

The MySQL module comes with predefined Kibana dashboards. To view your dashboards for any of your Logit.io stacks, 
launch Logs and choose Dashboards.
        
![Predefined kibana dashboard screenshot](@/images/integrations/filebeat/mysql.png)

### MySQL Logging Overview

MySQL is an open source relational database management system created by Michael Widenius in 1995, 
this relational database runs across the majority of operating systems & is closely associated with 
its usage for web applications.

MySQL powers some of the world's highest traffic sites, including Facebook, YouTube & Pinterest.

MySQL is able to work within an operating system to organise data into multiple data tables and show 
which data types may be related to each other. This helps the user to easily structure their data. 

When used in this way, relational databases can be used to test database integrity, manage users 
and create backups of vital data.

MySQL Servers create numerous logs that you can use for troubleshooting and analysis, the most 
important ones include: Slow query logs, General query logs & error logs.

These logs default to a text file format, which can quickly become tedious to parse and process 
quickly to spot functional problems, opportunities to improve performance and identify security issues.

Our built in HA (high availability) MySQL [log file analyser](https://logit.io/solutions/analysis/log-analysis) 
can be used to centralise your data & set up alerts to monitor your log data in real-time as well as deliver 
metrics for Kibana visualisations & reports with easily.