---
title: MySQL Server Metrics
subTitle: Ship your MySQL Server Metrics via Telegraf to your Logit.io Stack
logo: mysql
color: "#4d4d4d"
description: Use our example to configure Telegraf to ship MySQL Server metrics to Logit.io. Configure Telegraf to send MySQL Server metrics to Logstash or Elastic.
stackTypes: metrics
sslPortType: beats-ssl
---

Configure Telegraf to ship MySQL Server metrics to your Logit.io stacks via Logstash.

<Steps>
  ### Install Integration
  <InstallIntegration/>
  ### Install Telegraf

  <InstallTelegraf />

  ### Configure the Telegraf input plugin

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `/etc/telegraf/telegraf.conf` from the previous step.

  ```yaml copy
  # Read metrics from one or many mysql servers
  [[inputs.mysql]]
    ## specify servers via a url matching:
    ##  [username[:password]@][protocol[(address)]]/[?tls=[true|false|skip-verify|custom]]
    ##  see https://github.com/go-sql-driver/mysql#dsn-data-source-name
    ##  e.g.
    ##    servers = ["user:passwd@tcp(127.0.0.1:3306)/?tls=false"]
    ##    servers = ["user@tcp(127.0.0.1:3306)/?tls=false"]
    #
    ## If no servers are specified, then localhost is used as the host.
    servers = ["tcp(127.0.0.1:3306)/"]

    ## Selects the metric output format.
    ##
    ## This option exists to maintain backwards compatibility, if you have
    ## existing metrics do not set or change this value until you are ready to
    ## migrate to the new format.
    ##
    ## If you do not have existing metrics from this plugin set to the latest
    ## version.
    ##
    ## Telegraf >=1.6: metric_version = 2
    ##           <1.6: metric_version = 1 (or unset)
    metric_version = 2

    ## if the list is empty, then metrics are gathered from all database tables
    # table_schema_databases = []

    ## gather metrics from INFORMATION_SCHEMA.TABLES for databases provided
    ## in the list above
      gather_table_schema = true

    ## gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST
      gather_process_list = true

    ## gather user statistics from INFORMATION_SCHEMA.USER_STATISTICS
      gather_user_statistics = true

    ## gather auto_increment columns and max values from information schema
      gather_info_schema_auto_inc = true

    ## gather metrics from INFORMATION_SCHEMA.INNODB_METRICS
      gather_innodb_metrics = true

    ## gather metrics from all channels from SHOW SLAVE STATUS command output
    # gather_all_slave_channels = false

    ## gather metrics from SHOW SLAVE STATUS command output
      gather_slave_status = true

    ## use SHOW ALL SLAVES STATUS command output for MariaDB
    # mariadb_dialect = false

    ## gather metrics from SHOW BINARY LOGS command output
      gather_binary_logs = true

    ## gather metrics from SHOW GLOBAL VARIABLES command output
      gather_global_variables = true

    ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE
      gather_table_io_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS
      gather_table_lock_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE
      gather_index_io_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS
      gather_event_waits = true

    ## gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME
      gather_file_events_stats = true

    ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST
    # gather_perf_events_statements = false
    #
    ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_ACCOUNT_BY_EVENT_NAME
      gather_perf_sum_per_acc_per_event = true
    #
    ## list of events to be gathered for gather_perf_sum_per_acc_per_event
    ## in case of empty list all events will be gathered
    # perf_summary_events = []

    ## the limits for metrics form perf_events_statements
    # perf_events_statements_digest_text_limit = 120
    # perf_events_statements_limit = 250
    # perf_events_statements_time_limit = 86400

    ## Some queries we may want to run less often (such as SHOW GLOBAL VARIABLES)
    ##   example: interval_slow = "30m"
    # interval_slow = ""

    ## Optional TLS Config (used if tls=custom parameter specified in server uri)
    # tls_ca = "/etc/telegraf/ca.pem"
    # tls_cert = "/etc/telegraf/cert.pem"
    # tls_key = "/etc/telegraf/key.pem"
    ## Use TLS but skip chain & host verification
    # insecure_skip_verify = false
  ```

  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [MySQL](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/mysql)
  </Callout>

  ### Configure the output plugin

  <TelegrafOutputPlugin />

  ### Start Telegraf

  <StartTelegraf />

  ### View your metrics
  <LaunchStack source="MySQL_Server_Metrics_via_Telegraf" utmMedium="metrics" utmCampaign="telegraf-MySQL-metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### Telegraf MySQL Overview

To effectively monitor and analyze MySQL metrics in a distributed system, businesses need a trustworthy and proficient solution for managing metrics. 
Telegraf, an open-source server agent for collecting metrics, can amass MySQL metrics from a variety of sources, including live MySQL instances, 
databases, and other software applications.

With an extensive assortment of input plugins, Telegraf allows users to gather metrics from various resources, such as CPU usage, memory consumption, 
network traffic, and more. To store and scrutinize the collected metrics, businesses can employ Prometheus, an open-source monitoring and alerting 
tool that provides a flexible querying language and visual data representation capabilities.

By setting up Telegraf to output metrics in the Prometheus format and utilizing Prometheus to extract the metrics from the Telegraf server, 
companies can transfer MySQL metrics from Telegraf to Prometheus. This process involves configuring Telegraf to accumulate MySQL metrics, 
rendering them in the Prometheus format, arranging Prometheus to scrape the metrics from the Telegraf server, and visually interpreting 
the data using Prometheus's dynamic querying and data visualization features.

Using Telegraf to send MySQL metrics to Prometheus is a reliable and effective solution for managing metrics in distributed systems. 
It empowers organizations to gain insights into MySQL performance, enhance the efficiency of their distributed MySQL instances, 
and troubleshoot any potential issues swiftly.

If you need any further assistance with shipping your log data to Logit.io we're here to help you get started. 
Feel free to get in contact with our support team by sending us a message via <IntercomButton text="live chat" /> 
& we'll be happy to assist.