---
title: HAProxy
metaTitle: Learn How to Integrate and Configure Filebeat to Send HAProxy Logs
subTitle: Ship logs from HAProxy to Logstash
logo: haproxy
color: "#009edb"
description: Use Filebeat to send HAProxy application, access or error logs to your ELK stacks. Configure Filebeat to send HAProxy logs to logstash or Elasticsearch. 
stackTypes: logs, metrics
sslPortType: beats-ssl
tags: Logs, HAProxy, Proxy, Load Balancer, Ingress, HTTP, Web Server, Web Traffic, Haproxy, Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation
dashboardIds: haproxy, syslog
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Logs

  Configure Filebeat to ship logs from HAProxy to Logstash and Elasticsearch.

  ### Install Integration
  <InstallIntegration/>
  ### Install Filebeat

  <InstallFilebeat exclude={["Windows (Powershell)"]} />

  ### Setup HAProxy Configuration

  __DEB__ *(Debian/Ubuntu)*
          
  HAProxy generates logs in syslog format, on debian and ubuntu the haproxy package contains the required syslog configuration to generate a haproxy.log file which we will then monitor using filebeat.
  Confirm the existence of /etc/rsyslog.d/49-haproxy.conf and /var/log/haproxy.log
  If you've recently installed haproxy you may need to restart rsyslog to get additional haproxy config file loaded.

  __RPM__ *(Centos/RHEL)*

  The RPM haproxy default configuration sends it's logs to a syslog daemon listening on localhost via UDP. We need to configure rsyslog to listen on localhost and write a haproxy.log file which we will then monitor using filebeat. Run the following lines of command and then restart rsyslog.

  ```cmd copy
  echo '#Rsyslog configuration to listen on localhost for HAProxy log messages 
  #and write them to /var/log/haproxy.log
  $ModLoad imudp
  $UDPServerRun 514
  $UDPServerAddress 127.0.0.1
  local2.*    /var/log/haproxy.log' | sudo tee /etc/rsyslog.d/haproxy.conf

  sudo systemctl restart rsyslog
  ```

  ### Enable the Haproxy module

  <Tabs items={["Ubuntu & Debian", "Red Hat & centOS", "macOS", "Linux binaries (64-bit)"]}>
    <Tab>
      ```cmd copy
      sudo filebeat modules list
      sudo filebeat modules enable haproxy
      ```
      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the haproxy.yml module file:

      ```yml copy
      # Module: haproxy
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-haproxy.html

      - module: haproxy
        # All logs
        log:
          enabled: true

          # Set which input to use between syslog (default) or file.
          #var.input:

          # Set custom paths for the log files. If left empty,
          # Filebeat will choose the paths depending on your OS.
          #var.paths:
      ```
      Additional module configuration can be done using the per module config files located in the modules.d folder, for haproxy we want to configure the haproxy module to read from file, uncomment and edit the `var.input` line to say

      ```cmd copy
      var.input: file
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the haproxy module:

      ```cmd copy
      sudo filebeat modules list
      sudo filebeat modules enable haproxy
      ```
      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the haproxy.yml module file:

      ```yml copy
      # Module: haproxy
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-haproxy.html

      - module: haproxy
        # All logs
        log:
          enabled: true

          # Set which input to use between syslog (default) or file.
          # var.input:

          # Set custom paths for the log files. If left empty,
          # Filebeat will choose the paths depending on your OS.
          # var.paths:
      ```
      Additional module configuration can be done using the per module config files located in the modules.d folder, for haproxy we want to configure the haproxy module to read from file, uncomment and edit the `var.input` line to say

      ```cmd copy
      var.input: file
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the haproxy module:

      ```cmd copy
      ./filebeat modules list
      ./filebeat modules enable haproxy
      ```
      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the haproxy.yml module file:

      ```yml copy
      # Module: haproxy
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-haproxy.html

      - module: haproxy
        # All logs
        log:
          enabled: true

          # Set which input to use between syslog (default) or file.
          # var.input:

          # Set custom paths for the log files. If left empty,
          # Filebeat will choose the paths depending on your OS.
          # var.paths:
      ```
      Additional module configuration can be done using the per module config files located in the modules.d folder, for haproxy we want to configure the haproxy module to read from file, uncomment and edit the `var.input` line to say

      ```cmd copy
      var.input: file
      ```
    </Tab>
    <Tab>
      There are several built in filebeat modules you can use. You will need to enable the haproxy module:

      ```cmd copy
      ./filebeat modules list
      ./filebeat modules enable haproxy
      ```
      In the module config under modules.d, change the module settings to match your environment. You must enable at least one fileset in the module. 
      
      ___Filesets are disabled by default___.

      Copy the snippet below and replace the contents of the haproxy.yml module file:

      ```yml copy
      # Module: haproxy
      # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12/filebeat-module-haproxy.html

      - module: haproxy
        # All logs
        log:
          enabled: true

          # Set which input to use between syslog (default) or file.
          # var.input:

          # Set custom paths for the log files. If left empty,
          # Filebeat will choose the paths depending on your OS.
          # var.paths:
      ```
      Additional module configuration can be done using the per module config files located in the modules.d folder, for haproxy we want to configure the haproxy module to read from file, uncomment and edit the `var.input` line to say

      ```cmd copy
      var.input: file
      ```
    </Tab>
  </Tabs>

  ### Update Your Configuration File

  The configuration file below is pre-configured to send data to your Logit.io Stack via Logstash.

  Copy the configuration file below and overwrite the contents of filebeat.yml.

  ```yml copy filename="filebeat.yml" showLineNumbers /@logstash.host/ /@logstash.sslPort/
  ###################### Logit.io Filebeat Configuration ########################
  # ============================== Filebeat inputs ==============================

  # ============================== Filebeat modules ==============================
  filebeat.config.modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false
    #reload.period: 10s

  # ================================= Processors =================================
  processors:
    - add_host_metadata:
        when.not.contains.tags: forwarded
    - add_cloud_metadata: ~
    - add_docker_metadata: ~
    - add_kubernetes_metadata: ~

  # ================================== Outputs ===================================
  # ------------------------------ Logstash Output -------------------------------
  output.logstash:
    hosts: ["@logstash.host:@logstash.sslPort"]
    loadbalance: true
    ssl.enabled: true
  ```
  ### Validate Configuration

  <ValidateBeat beatname="filebeat" exclude={["Windows (Powershell)"]} />
  
  ### Start filebeat

  <StartFilebeat exclude={["Windows (Powershell)"]} />

  ### Launch OpenSearch Dashboards to View Your Data

  <LaunchVisualizer type="logs" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

  ### HAProxy dashboard

  ![Predefined kibana dashboard screenshot](@/images/integrations/filebeat/haproxy.png)
</Steps>

<Steps>
  ## Metrics

  Configure Telegraf to ship HAproxy metrics to your Logit.io stacks via Logstash.
  
  ### Install Integration
  <InstallIntegration/>

  ### Install Telegraf

  <InstallTelegraf exclude={["Windows (Powershell)"]} />

  ### Configure Telegraf

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `telegraf.conf` from the previous step.

  ```toml copy filename="telegraf.conf" showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  ### Read metrics of HAProxy, via stats socket or http endpoints
  [[inputs.haproxy]]
    ## List of stats endpoints. Metrics can be collected from both http and socket
    ## endpoints. Examples of valid endpoints:
    ##   - http://myhaproxy.com:1936/haproxy?stats
    ##   - https://myhaproxy.com:8000/stats
    ##   - socket:/run/haproxy/admin.sock
    ##   - /run/haproxy/*.sock
    ##   - tcp://127.0.0.1:1936
    ##
    ## Server addresses not starting with 'http://', 'https://', 'tcp://' will be
    ## treated as possible sockets. When specifying local socket, glob patterns are
    ## supported.
    servers = ["http://myhaproxy.com:1936/haproxy?stats"]

    ## By default, some of the fields are renamed from what haproxy calls them.
    ## Setting this option to true results in the plugin keeping the original
    ## field names.
    # keep_field_names = false

    ## Optional TLS Config
    # tls_ca = "/etc/telegraf/ca.pem"
    # tls_cert = "/etc/telegraf/cert.pem"
    # tls_key = "/etc/telegraf/key.pem"
    ## Use TLS but skip chain & host verification
    # insecure_skip_verify = false

  ### System metrics
  [[inputs.disk]]
  [[inputs.net]]
  [[inputs.mem]]
  [[inputs.system]]
  [[inputs.cpu]]
    percpu = false
    totalcpu = true
    collect_cpu_time = true
    report_active = true

  ### Output
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"

    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```

  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [HAproxy](https://github.com/influxdata/telegraf/blob/master/plugins/inputs/haproxy/README.md)
  </Callout>

  ### Start Telegraf

  <StartTelegraf exclude={["Windows (Powershell)"]} />

  ### Launch Grafana to View Your Data

  <LaunchVisualizer type="metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### HAProxy Logs Overview

HAProxy (High Availability Proxy) is an open-source software load balancer for 
proxying [HTTP](/integrations/http) & [TCP](/integrations/tcp) based 
applications. As the tool offers high availability by default it is well suited 
for high traffic websites. HAProxy is the de-facto proxy server powering many of 
the web's most popular sites & is often the default deployment in most cloud platforms. 

For most Linux distributions it is the reference load-balancer recommended for container 
orchestration (E.G [Kubernetes](/integrations/kubernetes)).
HAProxy logs hold data on HTTP queries, error codes & how long the request took to send, 
if it was queued and how long for, how long the TCP connection took to establish, as well 
as information on response size and cookies, among other valuable insights for reporting & 
security. These logs can be difficult to process for analysis at scale & so a log analyser 
will likely be required to process HAProxy logs efficiently. 

Requests & traffic for HTTP & TCP based applications are spread across multiple servers 
when HAProxy is used. The proxy is well known for its flexibility & the tool's logs can 
be used in a log management solution such as Logit.io for easy identification of critical 
issues within an application. The Logit.io platform offers a complete solution for 
centralising your log files from multiple applications and servers and provides a HAProxy 
log analyser as standard. You can also use our Kibana integrations to visualise key server 
metrics from both frontend and backend applications for fast error resolution & troubleshooting.
Followed our HAProxy log configuration guide and are still encountering issues? We're here 
to help you get started. Feel free to reach out by contacting our support team by visiting 
our dedicated Help Centre or via live chat & we'll be happy to assist.