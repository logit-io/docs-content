---
title: Red Hat
metaTitle: Learn How to Integrate and Configure Filebeat to Send Red Hat Logs
pageTitle: Red Hat (RHEL) System Logs
subTitle: Ship system log files from Red Hat Enterprise Linux (RHEL) to Logstash
logo: redhat
color: "#ee0000"
description: Use Filebeat to send Red Hat application, access and system logs to your ELK stacks. Configure Filebeat to send Red Hat system logs to Elasticsearch. 
stackTypes: logs
sslPortType: beats-ssl
tags: Logs, RedHat, Red Hat, RHEL, Fedora, Linux Distribution, Redhat
dashboardIds: syslog
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Logs

  Configure Filebeat to ship logs from Red Hat Systems to Logstash and Elasticsearch.
  
  ### Install Integration
  <InstallIntegration/>
  ### Install Filebeat

  <InstallFilebeat include={["Red Hat & centOS"]} />

  ### Enable The System Module

  There are several built in filebeat modules you can use. You will need to enable the system module.

  Change directory to the location where filebeat was extracted and run the following commands:

  ```bash copy
  sudo filebeat modules list
  sudo filebeat modules enable system
  ```
  Navigate to the `modules.d` folder, copy the snippet below and replace the contents of the system.yml module file:

  ```yaml copy
  # Module: system
  # Docs: https://www.elastic.co/guide/en/beats/filebeat/8.12.2/filebeat-module-system.html

  - module: system
    # Syslog
    syslog:
      enabled: true

      # Set custom paths for the log files. If left empty,
      # Filebeat will choose the paths depending on your OS.
      #var.paths:

    # Authorization logs
    auth:
      enabled: true

      # Set custom paths for the log files. If left empty,
      # Filebeat will choose the paths depending on your OS.
      #var.paths:
  ```

  ### Update your configuration file

  The configuration file below is pre-configured to send data to your Logit.io Stack via Logstash.

  Copy the configuration file below and overwrite the contents of `filebeat.yml` 
  (this file can be found in the folder where you installed Filebeat in the first step).

  <Callout type="info">
    Filebeat modules offer the quickest way to begin working with standard log formats. 
    If you opt to configure Filebeat manually rather than utilizing modules, you'll do so by 
    listing inputs in the filebeat.inputs section of filebeat.yml. These inputs detail 
    how Filebeat discovers and handles input data. 
  </Callout>
    
```yml copy filename="filebeat.yml" showLineNumbers /@logstash.host/ /@logstash.sslPort/
  ###################### Logit.io Filebeat Configuration ########################
  # ============================== Filebeat inputs ==============================
  filebeat.inputs:
  - type: filestream
    enabled: true
    id: my_unique_id
    paths:
      # REQUIRED CHANGE TO YOUR LOGS PATH
      - /var/log/*.log
    fields:
      type: logfile
      
  # ============================== Filebeat modules ==============================
  filebeat.config.modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false
    #reload.period: 10s

  # ================================= Processors =================================
  processors:
    - add_host_metadata:
        when.not.contains.tags: forwarded
    - add_cloud_metadata: ~
    - add_docker_metadata: ~
    - add_kubernetes_metadata: ~

  # ================================== Outputs ===================================
  # ------------------------------ Logstash Output -------------------------------
  output.logstash:
    hosts: ["@logstash.host:@logstash.sslPort"]
    loadbalance: true
    ssl.enabled: true
  ```

  ### Validate Configuration

  <ValidateBeat beatname="filebeat" include={["Red Hat & centOS"]} />

  ### Start filebeat

  <StartFilebeat include={["Red Hat & centOS"]} />

  ### Launch OpenSearch Dashboards to View Your Data

  <LaunchVisualizer type="logs" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

  ### (Optional) Update Logstash Pipelines

  <LogstashPipeline />
  
</Steps>
<Steps>
  ## Metrics

  Configure Telegraf to ship your system metrics to Logit.io.
  
  ### Install Integration

  <InstallIntegration/>

  ### Install Telegraf

  <InstallTelegraf include={["Red Hat & centOS"]} />

  ### Configure the plugin

  The configuration below will scrape a selection of system metrics from the machine you have installed Telegraf 
  on and these will be sent to your Logit.io stack. Metrics include CPU, memory and disk usage and system metrics 
  such as system load and uptime.


  ```toml copy filename="telegraf.conf" showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  # Read metrics about cpu usage
  [[inputs.cpu]]
    ## Whether to report per-cpu stats or not
    percpu = true
    ## Whether to report total system cpu stats or not
    totalcpu = true
    ## If true collect raw cpu time metrics
    collect_cpu_time = true
    ## If true compute and report the sum of all non-idle cpu states
    report_active = true
  
  # Read metrics about memory usage
  [[inputs.mem]]
  
  # Read metrics about system load & uptime
  [[inputs.system]]
    namepass = ["system"]
  
  # Read metrics about disk usage by mount point
  [[inputs.disk]]
    ## By default, telegraf gather stats for all mountpoints.
    ## Setting mountpoints will restrict the stats to the specified mountpoints.
    # mount_points = ["/"]

    ## Ignore some mountpoints by filesystem type. For example (dev)tmpfs (usually
    ## present on /run, /var/run, /dev/shm or /dev).
    ignore_fs = ["tmpfs", "devtmpfs"]
  
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"
  
    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```

  ### Start Telegraf

  <StartTelegraf include={["Red Hat & centOS"]} />

  ### Launch Metrics to View Data

  Click the 'Launch Metrics' button below to open the infrastructure metrics visualizer. 
  
  <LaunchVisualizer type="metrics" />
  
  Now, as a simple demonstration we will use Grafana to view some metrics data that is being sent to your Logit.io stack. 

  Once Grafana has been opened, click on the Explore option in the left-hand menu:
  ![Grafana Explore](@/images/integrations/system-metrics/grafana-explore.png)
  
  Under the Metric header you will see 'Select metric'. Open the drop-down menu 
  and scroll to and select 'mem_available':

  ![Grafana Select Metric](@/images/integrations/system-metrics/grafana-metrics-mem.png)

  Click on the blue Run query button near the top-right of the screen:

  ![Grafana Run Query](@/images/integrations/system-metrics/grafana-run-query.png)

  You will now see the metric data displayed and if you click on the blue Run query button this will be updated.
  You can set this to automatically update by clicking on the arrow on the blue button and chosing the interval 
  at which you want the data to be updated.

  When you want to stop Telegraf sending metric data press Ctrl + C in the terminal app / Powershell.

  To learn more about Grafana Dashboard click [here](../getting-started/grafana-dashboards/).

</Steps>

### Red Hat Logging Overview

Red Hat Enterprise Linux (RHEL) is the most popular commercial Linux 
distribution used in public cloud environments. 

Red Hat Enterprise Linux is often compared to [CentOS](/integrations/centos). 
The main difference between the two Linux distributions is that RHEL 
offers a much more comprehensive level of technical support to their users.

Red Hat Enterprise Linux generates a near overwhelming amount of log 
files under the `/var/log/` directory. Just under `/var/log/messages` 
alone there are mail, cron, daemon, kern & authentication logs. 

Below are some of the most notable log directories that you'll commonly encounter.

If you are using custom-built Kernels then you'll likely need to analyse the logs 
contained under /var/log/kern.log when it comes to troubleshooting your application.

The log messages found under /var/log/secure are relevant for monitoring the 
security of your Linux distribution as they contain authentication events, 
login attempts & authorisation log events.

You may also wish to consult  /var/log/setroubleshoot/ to discover issues related 
to the security context of logs files created under this directory.

With over 25 different log directories anyone would quickly find analysing their 
Red Hat system overwhelming without a log file analyser as part of a 
centralised [log management solution](https://logit.io/platform/logging/log-management/).

Our HA (highly available) Red Hat log file analyser can be used to completely 
centralise and manage your log file data across Red Hat & any additional applications, 
servers & programming languages for a single source of truth for monitoring across your organisation.

If you need any assistance with analysing your Red Hat logs we're here to help. 
Feel free to reach out by contacting the Logit.io support team 
via <IntercomButton text="live chat" /> & we'll be happy to help you start analysing your data.
      
