---
title: Prometheus
metaTitle: Integrate and Configure Telegraf to send Prometheus Metrics
subTitle: Ship your Prometheus Metrics via Telegraf to your Logit.io Stack
logo: prometheus
color: "#4d4d4d"
description: Use our example to configure Telegraf to ship Prometheus metrics to your Logit.io stacks. Configure Telegraf to send Prometheus metrics to Logstash or Elastic.
stackTypes: metrics
sslPortType: beats-ssl
tags: Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation, Prometheus, Monitoring
---

TODO: Add description

<Steps>
  ## Metrics

  Configure Telegraf to ship Prometheus metrics to your Logit.io stacks via Logstash.
  
  ### Install Integration
  <InstallIntegration/>
  ### Install Telegraf

  <InstallTelegraf />

  ### Configure the Telegraf input plugin

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `/etc/telegraf/telegraf.conf` from the previous step.

  ```toml copy
  # Read metrics from one or many prometheus clients
  [[inputs.prometheus]]
  ## An array of urls to scrape metrics from.
    urls = ["http://localhost:9100/metrics"]

    ## Metric version controls the mapping from Prometheus metrics into Telegraf metrics.
    ## See "Metric Format Configuration" in plugins/inputs/prometheus/README.md for details.
    ## Valid options: 1, 2
    # metric_version = 1

    ## Url tag name (tag containing scrapped url. optional, default is "url")
    # url_tag = "url"

    ## Whether the timestamp of the scraped metrics will be ignored.
    ## If set to true, the gather time will be used.
    # ignore_timestamp = false

    ## An array of Kubernetes services to scrape metrics from.
    # kubernetes_services = ["http://my-service-dns.my-namespace:9100/metrics"]

    ## Kubernetes config file to create client from.
    # kube_config = "/path/to/kubernetes.config"

    ## Scrape Pods
    ## Enable scraping of k8s pods. Further settings as to which pods to scape
    ## are determiend by the 'method' option below. When enabled, the default is
    ## to use annotations to determine whether to scrape or not.
    # monitor_kubernetes_pods = false

    ## Scrape Pods Method
    ## annotations: default, looks for specific pod annotations documented below
    ## settings: only look for pods matching the settings provided, not
    ##   annotations
    ## settings+annotations: looks at pods that match annotations using the user
    ##   defined settings
    # monitor_kubernetes_pods_method = "annotations"

    ## Scrape Pods 'annotations' method options
    ## If set method is set to 'annotations' or 'settings+annotations', these
    ## annotation flags are looked for:
    ## - prometheus.io/scrape: Required to enable scraping for this pod. Can also
    ##     use 'prometheus.io/scrape=false' annotation to opt-out entirely.
    ## - prometheus.io/scheme: If the metrics endpoint is secured then you will
    ##     need to set this to 'https' & most likely set the tls config
    ## - prometheus.io/path: If the metrics path is not /metrics, define it with
    ##     this annotation
    ## - prometheus.io/port: If port is not 9102 use this annotation

    ## Scrape Pods 'settings' method options
    ## When using 'settings' or 'settings+annotations', the default values for
    ## annotations can be modified using with the following options:
    # monitor_kubernetes_pods_scheme = "http"
    # monitor_kubernetes_pods_port = "9102"
    # monitor_kubernetes_pods_path = "/metrics"

    ## Get the list of pods to scrape with either the scope of
    ## - cluster: the kubernetes watch api (default, no need to specify)
    ## - node: the local cadvisor api; for scalability. Note that the config node_ip or the environment variable NODE_IP must be set to the host IP.
    # pod_scrape_scope = "cluster"

    ## Only for node scrape scope: node IP of the node that telegraf is running on.
    ## Either this config or the environment variable NODE_IP must be set.
    # node_ip = "10.180.1.1"

    ## Only for node scrape scope: interval in seconds for how often to get updated pod list for scraping.
    ## Default is 60 seconds.
    # pod_scrape_interval = 60

    ## Restricts Kubernetes monitoring to a single namespace
    ##   ex: monitor_kubernetes_pods_namespace = "default"
    # monitor_kubernetes_pods_namespace = ""
    ## The name of the label for the pod that is being scraped.
    ## Default is 'namespace' but this can conflict with metrics that have the label 'namespace'
    # pod_namespace_label_name = "namespace"
    # label selector to target pods which have the label
    # kubernetes_label_selector = "env=dev,app=nginx"
    # field selector to target pods
    # eg. To scrape pods on a specific node
    # kubernetes_field_selector = "spec.nodeName=$HOSTNAME"

    ## Filter which pod annotations and labels will be added to metric tags
    #
    # pod_annotation_include = ["annotation-key-1"]
    # pod_annotation_exclude = ["exclude-me"]
    # pod_label_include = ["label-key-1"]
    # pod_label_exclude = ["exclude-me"]

    # cache refresh interval to set the interval for re-sync of pods list.
    # Default is 60 minutes.
    # cache_refresh_interval = 60

    ## Scrape Services available in Consul Catalog
    # [inputs.prometheus.consul]
    #   enabled = true
    #   agent = "http://localhost:8500"
    #   query_interval = "5m"

    ## Use bearer token for authorization. ('bearer_token' takes priority)
    # bearer_token = "/path/to/bearer/token"
    ## OR
    # bearer_token_string = "abc_123"

    ## HTTP Basic Authentication username and password. ('bearer_token' and
    ## 'bearer_token_string' take priority)
    # username = ""
    # password = ""

    ## Optional custom HTTP headers
    # http_headers = {"X-Special-Header" = "Special-Value"}

    ## Specify timeout duration for slower prometheus clients (default is 5s)
    # timeout = "5s"

    ## deprecated in 1.26; use the timeout option
    # response_timeout = "5s"

    ## HTTP Proxy support
    # use_system_proxy = false
    # http_proxy_url = ""

    ## Optional TLS Config
    # tls_ca = /path/to/cafile
    # tls_cert = /path/to/certfile
    # tls_key = /path/to/keyfile

    ## Use TLS but skip chain & host verification
    # insecure_skip_verify = false

    ## Use the given name as the SNI server name on each URL
    # tls_server_name = "myhost.example.org"

    ## TLS renegotiation method, choose from "never", "once", "freely"
    # tls_renegotiation_method = "never"

    ## Enable/disable TLS
    ## Set to true/false to enforce TLS being enabled/disabled. If not set,
    ## enable TLS only if any of the other options are specified.
    # tls_enable = true

    ## Control pod scraping based on pod namespace annotations
    ## Pass and drop here act like tagpass and tagdrop, but instead
    ## of filtering metrics they filters pod candidates for scraping
    #[inputs.prometheus.namespace_annotation_pass]
    # annotation_key = ["value1", "value2"]
    #[inputs.prometheus.namespace_annotation_drop]
    # some_annotation_key = ["dont-scrape"]
  ```
  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [Prometheus](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/prometheus/README.md)
  </Callout>

  ### Configure the output plugin

  <TelegrafOutputPlugin />

  ### Start Telegraf

  <StartTelegraf />

  ### View your metrics
  <LaunchStack source="Prometheus_Metrics_via_Telegraf" utmMedium="metrics" utmCampaign="telegraf-Prometheus-metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### Telegraf Prometheus metrics Overview

To effectively monitor and analyze metrics in a distributed environment, organizations require a reliable 
and efficient metrics management solution. Prometheus, an open-source monitoring and alerting tool, 
is the ideal choice for collecting and storing metrics from diverse sources such as applications, servers, databases, and more.

Prometheus offers a flexible architecture and robust features to gather a comprehensive set of metrics 
including CPU usage, memory utilization, network activity, response times, and more. 
These metrics provide valuable insights into the performance and health of distributed systems.

To efficiently collect and store metrics, organizations can leverage Telegraf, an open-source metrics collection agent. 
Telegraf provides a wide range of input plugins to gather metrics from various sources. 
By configuring Telegraf to output metrics in the Prometheus format and utilizing Prometheus's scraping capabilities, 
organizations can seamlessly ship metrics from Telegraf to Prometheus.

The process involves setting up Telegraf to collect metrics, formatting them in the Prometheus format, 
configuring Prometheus to scrape the metrics from the Telegraf server, and utilizing Prometheus's 
advanced querying and graphical visualization capabilities for data analysis and visualization.

Using Telegraf to ship metrics to Prometheus ensures a reliable and efficient metrics management solution 
in distributed environments. It empowers organizations to gain valuable insights into system performance, 
optimize resource allocation, identify bottlenecks, and proactively address issues.

Prometheus's robust storage, querying, and visualization capabilities, coupled with Telegraf's flexibility 
in metric collection, make them a powerful combination for effective metrics monitoring and analysis in 
distributed environments. By leveraging Prometheus and Telegraf, organizations can confidently monitor 
their systems, make data-driven decisions, and ensure optimal performance and reliability.

If you need any further assistance with shipping your log data to Logit.io we're here to help you get started. 
Feel free to get in contact with our support team by sending us a message via <IntercomButton text="live chat" /> 
& we'll be happy to assist.