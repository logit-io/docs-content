---
title: Nvidia SMI
metaTitle: Integrate and Configure Telegraf to send Nvidia SMI Metrics
subTitle: Ship your Nvidia SMI Metrics via Telegraf to your Logit.io Stack
logo: nvidia
color: "#4d4d4d"
description: Use our example to configure Telegraf to ship Nvidia SMI Metrics to your Logit.io stacks. Configure Telegraf to send Nvidia SMI Metrics to Logstash or Elastic.
stackTypes: metrics
sslPortType: beats-ssl
tags: Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation, Nvidia, GPU, Monitoring, Hardware
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Metrics

  Configure Telegraf to ship Nvidia SMI Metrics to your Logit.io stacks via Logstash.
  
  ### Install Integration
  <InstallIntegration/>
  ### Install Telegraf

  <InstallTelegraf />

  ### Configure the Telegraf input plugin

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `telegraf.conf` from the previous step.

  ```toml copy showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  # Pulls statistics from nvidia GPUs attached to the host
  [[inputs.nvidia_smi]]
    ## Optional: path to nvidia-smi binary, defaults "/usr/bin/nvidia-smi"
    ## We will first try to locate the nvidia-smi binary with the explicitly specified value (or default value),
    ## if it is not found, we will try to locate it on PATH(exec.LookPath), if it is still not found, an error will be returned
    # bin_path = "/usr/bin/nvidia-smi"

    ## Optional: timeout for GPU polling
    # timeout = "5s"

  ### System metrics
  [[inputs.disk]]
  [[inputs.net]]
  [[inputs.mem]]
  [[inputs.system]]
  [[inputs.cpu]]
    percpu = false
    totalcpu = true
    collect_cpu_time = true
    report_active = true

  ### Output
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"

    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```
  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [Nvidia SMI](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/nvidia_smi)
  </Callout>

  ### Start Telegraf

  <StartTelegraf />

  ### View your metrics
  <LaunchStack source="Nvidia_SMI_Metrics_via_Telegraf" utmMedium="metrics" utmCampaign="telegraf-NvidiaSMI-metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### Telegraf Nvidia SMI Overview

To efficiently monitor and analyze Nvidia SMI metrics across different systems, it's vital to implement a robust and 
efficient metrics management solution. Telegraf, an open-source server agent designed for collecting and reporting 
metrics, fits this role perfectly. It can gather Nvidia SMI metrics from various sources, including operational 
Nvidia SMI instances, databases, and other relevant applications.
      
Telegraf's array of input plugins enables users to collect a variety of metrics, like CPU usage, memory utilization, 
network traffic, and more, all vital for understanding Nvidia SMI performance. To store and analyze these harvested 
metrics, organizations can utilize Prometheus, an open-source monitoring and alerting toolkit renowned for its 
flexible querying language and powerful data visualization capabilities.

To channel Nvidia SMI metrics from Telegraf to Prometheus, organizations need to configure Telegraf to output metrics 
in the Prometheus format, and then set up Prometheus to scrape these metrics from the Telegraf server. This process 
involves setting up Telegraf to collect Nvidia SMI metrics, outputting them in the Prometheus format, configuring 
Prometheus to retrieve these metrics from the Telegraf server, and then visually interpreting the data using 
Prometheus's dynamic querying and graphical visualization tools.

Once the metrics are successfully integrated into Prometheus, further analysis and visualization can be performed 
using Grafana. Grafana, a leading open-source platform known for its monitoring and observability features, is 
fully compatible with Prometheus. It enables users to create dynamic, interactive dashboards for a deep dive into 
the metrics data, providing a comprehensive understanding of performance trends and potential issues in the Nvidia SMI system.

If you need any further assistance with shipping your log data to Logit.io we're here to help you get started. 
Feel free to get in contact with our support team by sending us a message via <IntercomButton text="live chat" /> 
& we'll be happy to assist.