---
title: Jenkins
metaTitle: Learn How to Send Jenkins Logs and Metrics to Logit.io
subTitle: Ship Jenkins logs and Metrics to Logit.io
logo: jenkins
color: "#4d4d4d"
description: Send your Jenkins logs and metrics to logit.io using the instructions below and begin searching your data
stackTypes: logs, metrics
sslPortType: beats-ssl
tags: Automation, Deployment, CI/CD, Jenkins, Telegraf, Metrics, Telemetry, OpenTelemetry, Health, Instrumentation, Continuous Integration
---

Follow the steps below to send your observability data to Logit.io

<Steps>
  ## Logs

  Send your Jenkins logs to logit.io via Logstash using the instructions below and begin searching your data.

  ### Install Integration
  <InstallIntegration/>
  ### Install Filebeat

  <InstallFilebeat />

  ### Configure Filebeat

  Copy and use the Filebeat configuration below.

  Remember to update your Jenkins log file path if it is in a different location to the below configuration.

  ```yml copy filename="filebeat.yml" showLineNumbers /@logstash.host/ /@logstash.sslPort/
  ###################### Logit.io Filebeat Configuration ########################
  # ============================== Filebeat inputs ==============================
  filebeat.inputs:
  - type: filestream
    paths:
      - /var/log/jenkins/jenkins.log
      #- /var/<JENKINS-DIRECTORY>/jobs/*/builds/lastFailedBuild/log
    fields:
      type: jenkins
    
    fields_under_root: true
    encoding: utf-8
    ignore_older: 3h
    
    multiline:
      pattern: '^[A-Z]{1}[a-z]{2} {1,2}[0-9]{1,2}, [0-9]{4} {1,2}[0-9]{1,2}:[0-9]{2}:[0-9]{2}'
      negate: true
      match: after

  # ============================== Filebeat modules ==============================
  filebeat.config.modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false
    #reload.period: 10s

  # ================================= Processors =================================
  processors:
    - add_host_metadata:
        when.not.contains.tags: forwarded
    - add_cloud_metadata: ~
    - add_docker_metadata: ~
    - add_kubernetes_metadata: ~

  # ================================== Outputs ===================================
  # ------------------------------ Logstash Output -------------------------------
  output.logstash:
    hosts: ["@logstash.host:@logstash.sslPort"]
    loadbalance: true
    ssl.enabled: true
  ```
  
  ### Start filebeat
  
  <StartFilebeat />

  ### Launch Logit.io to view your logs
  <LaunchStack utmMedium="logs" utmCampaign="jenkins" source="jenkins" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />
</Steps>

<Steps>
  ## Metrics

  Configure Telegraf to ship Jenkins metrics to your Logit.io stack
  
  ### Install Integration
  <InstallIntegration/>

  ### Install Telegraf

  <InstallTelegraf />

  ### Configure the Telegraf input plugin

  The configuration file below is pre-configured to scrape the system metrics from your hosts, add the following code to the configuration file `telegraf.conf` from the previous step.

  ```toml copy showLineNumbers /@metricsUsername/ /@metricsPassword/ /@metrics_id/ /@vmAgentPort/
  ### Read jobs and cluster metrics from Jenkins instances
  [[inputs.jenkins]]
    ## The Jenkins URL in the format "schema://host:port"
    url = "http://my-jenkins-instance:8080"
    # username = "admin"
    # password = "admin"

    ## Set response_timeout
    response_timeout = "5s"

    ## Optional TLS Config
    # tls_ca = "/etc/telegraf/ca.pem"
    # tls_cert = "/etc/telegraf/cert.pem"
    # tls_key = "/etc/telegraf/key.pem"
    ## Use SSL but skip chain & host verification
    # insecure_skip_verify = false

    ## Optional Max Job Build Age filter
    ## Default 1 hour, ignore builds older than max_build_age
    # max_build_age = "1h"

    ## Optional Sub Job Depth filter
    ## Jenkins can have unlimited layer of sub jobs
    ## This config will limit the layers of pulling, default value 0 means
    ## unlimited pulling until no more sub jobs
    # max_subjob_depth = 0

    ## Optional Sub Job Per Layer
    ## In workflow-multibranch-plugin, each branch will be created as a sub job.
    ## This config will limit to call only the lasted branches in each layer,
    ## empty will use default value 10
    # max_subjob_per_layer = 10

    ## Jobs to include or exclude from gathering
    ## When using both lists, job_exclude has priority.
    ## Wildcards are supported: [ "jobA/*", "jobB/subjob1/*"]
    # job_include = [ "*" ]
    # job_exclude = [ ]

    ## Nodes to include or exclude from gathering
    ## When using both lists, node_exclude has priority.
    # node_include = [ "*" ]
    # node_exclude = [ ]

    ## Worker pool for jenkins plugin only
    ## Empty this field will use default value 5
    # max_connections = 5

  ### System metrics
  [[inputs.disk]]
  [[inputs.net]]
  [[inputs.mem]]
  [[inputs.system]]
  [[inputs.cpu]]
    percpu = false
    totalcpu = true
    collect_cpu_time = true
    report_active = true

  ### Output
  [[outputs.http]]
    url = "https://@metricsUsername:@metricsPassword@@metrics_id-vm.logit.io:@vmAgentPort/api/v1/write"
    data_format = "prometheusremotewrite"

    [outputs.http.headers]
      Content-Type = "application/x-protobuf"
      Content-Encoding = "snappy"
  ```

  <Callout type="info">
    Read more about how to configure data scraping and configuration options for [Jenkins](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jenkins)
  </Callout>

  ### Start Telegraf

  <StartTelegraf />

  ### View your metrics
  <LaunchStack source="Jenkins_Metrics_via_Telegraf" utmMedium="metrics" utmCampaign="telegraf-Jenkins-metrics" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>