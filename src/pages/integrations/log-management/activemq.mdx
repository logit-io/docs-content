---
title: ActiveMQ
subTitle: Collect and Ship ActiveMQ application logs to Logstash and Elasticsearch
logo: activemq
color: "#d10066"
description: Use Filebeat to send ActiveMQ application logs to your hosted ELK stacks. Get started using our Filebeat ActiveMQ example configurations.
stackTypes: logs
sslPortType: beats-ssl
---

Filebeat is a lightweight shipper that enables you to send your ActiveMQ message queue logs to Logstash and Elasticsearch. 
Configure Filebeat using the pre-defined examples below to start sending and analysing your ActiveMQ message queue logs.

<Steps>
  ### Install Integration
  <InstallIntegration/>
  ### Install Filebeat

  <InstallFilebeat items={["DEB", "RPM"]} />

  ### Locate Configuration File

  __deb/rpm__ `/etc/filebeat/filebeat.yml`

  ### Add ActiveMQ Log Location

  Filebeat does not currently have a module to process the ActiveMQ application logs.
          
  Therefore we need to add the ActiveMQ application log location to the filebeat inputs. 
  
  Add the following to the end of the log input example, before the `filebeat.config.modules` section.

  ```YML copy
  - type: log
      enabled: true
      paths:
      - /path/to/log/activemq/data/activemq.log*
      fields:
      type: activemq
      multiline.pattern: ^\=
      multiline.match: before
  ```
  
  If you're running Filebeat 8.1+ `filebeat.inputs` needs to be `filestream` instead of `logs`:

  ```yml copy
  filebeat.inputs:

  - type: filestream
      enabled: true
      paths:
      - /path/to/log/activemq/data/activemq.log*
      fields:
      type: activemq
      multiline.pattern: ^\=
      multiline.match: before
  ```

  ### Enable the input

  We need to ensure that any inputs we are using are enabled

  ```yml copy
  filebeat.inputs:

  - type: log
      enabled: false
  ```     

  Enable the filebeat input, so it should look like the following

  ```yml copy
  filebeat.inputs:

  - type: log
      enabled: true
  ```

  ### Configure Output

  We will be shipping to Logstash so that we have the option to run filters before the data is indexed.
          
  Comment out the elasticsearch output block.

  ```yml copy
  ## Comment out elasticsearch output
  #output.elasticsearch:
  #  hosts: ["localhost:9200"]
  ```
  <ConfigureOutput />

  ### Validate Configuration

  <ValidateBeat beatname="filebeat" />
  
  ### Start Filebeat

  <StartFilebeat />

  ### Launch Logit.io to view your logs

  <LaunchStack utmMedium="logs" utmCampaign="activemq" source="activemq" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />
  
</Steps>