---
title: HTTP/S
subTitle: Ship logs using HTTP/S to your Logit.io Stack
logo: https
color: "#30a743"
description: How to send HTTP endpoint server metrics to your Hosted ELK Logstash instance. Configure Metricbeat to send HTTP endpoint server metrics to Elasticsearch.
stackTypes: logs
---

Send HTTP/S logs to your Logit.io Stack via Logstash.

<Steps>
  ### Requirements

  - Valid JSON content
  - API key (find this on your dashboard) sent in the headers. If you are logged into your account the API key and Logit.io endpoint should be automatically populated in the examples below.
  - Content-Type header set as application/json
  - Either POST or PUT to https://@logitApiEndpoint/v2

  ### Example

  <Tabs items={["Windows", "Linux", "macOS", "DEB", "RPM"]}>
  <Tab>
  Remember that you will need to escape double-quote characters with a backslash in the data field as shown in the example below:
              
  CMD
  ```bash copy
  curl -i -H "ApiKey: {{apikey}}" -i -H "Content-Type: application/json" -H "LogType: json" https://{{logitApiEndpoint}}/v2 -d "{\"test\":\"test\",\"example\": { \"a\": 1, \"b\": 2 } }"
  ```

  Powershell
  ```ps1 copy
  curl -Method Post `
  -Uri "https://{{logitApiEndpoint}}/v2" `
  -Headers @{
      "ApiKey" = "{{apikey}}";
      "Content-Type" = "application/json";
      "LogType" = "json"
  } `
  -Body (@{
      test = "test";
      example = @{
          a = 1;
          b = 2
      }
  } | ConvertTo-Json)
  ```
  </Tab>

  <Tab>
  ```bash copy
  curl -i -H "ApiKey: {{apikey}}" -i -H "Content-Type: application/json" -H "LogType: json" https://{{logitApiEndpoint}}/v2 -d '{"test":"test","example": { "a": 1, "b": 2 } }'
  ```
  </Tab>

  <Tab>
  ```bash copy
  curl -i -H "ApiKey: {{apikey}}" -i -H "Content-Type: application/json" -H "LogType: json" https://{{logitApiEndpoint}}/v2 -d '{"test":"test","example": { "a": 1, "b": 2 } }'
  ```
  </Tab>

  <Tab>
  ```bash copy
  curl -i -H "ApiKey: {{apikey}}" -i -H "Content-Type: application/json" -H "LogType: json" https://{{logitApiEndpoint}}/v2 -d '{"test":"test","example": { "a": 1, "b": 2 } }'
  ```
  </Tab>

  <Tab>
  ```bash copy
  curl -i -H "ApiKey: {{apikey}}" -i -H "Content-Type: application/json" -H "LogType: json" https://{{logitApiEndpoint}}/v2 -d '{"test":"test","example": { "a": 1, "b": 2 } }'
  ```
  </Tab>

  </Tabs>

  ### Response

  You should expect to receive a 202 ACCEPTED response code for a successful message

  ```cmd copy
  HTTP/1.1 202 ACCEPTED
  Content-Type: application/json
  Content-Length: 39
  Connection: keep-alive
  Server: Logit-API-Server
  Date: Wed, 27 Mar 2024 14:34:39 GMT
  Access-Control-Allow-Origin: *
  Strict-Transport-Security: max-age=31536000; includeSubDomains
  X-Xss-Protection: 1; mode=block
  X-Content-Type-Options: nosniff
  X-Frame-Options: SAMEORIGIN

  {"message":"Message Received, Thanks"}
  ```

  ### Check Logit.io for your logs

  <LaunchStack utmMedium="logs" utmCampaign="http" source="http" />

  ### How to diagnose no data in Stack

  <DiagnoseNoData />

</Steps>

### HTTP/S Logging Overview

HTTP is a client-server protocol designed in the early 1990s & provides 
the foundation of all web data exchanges. Data is sent over the connection 
using [TCP](/integrations/logs/protocols/tcp) or over a TLS-encrypted connection.

All HTTP requests are stored as logs in a text file. You'll be able to locate 
all HTTP requests, access, status codes, server, & error logs in the 
logs directory below the server instance root directory.

Querying all of the various HTTP logs generated by your application 
can easily turn into an unnecessarily time-consuming task when scaling your 
log analysis for larger websites processing thousands of requests per day.

Using a centralised logging UI (user interface) for reporting & visualisations 
makes streaming & troubleshooting your HTTP/S logs far more efficient 
in comparison to dealing with numerous log files across distributed systems.

The Logit.io platform offers a complete platform for centralising your log 
files from multiple applications and servers and provides an HTTP logger 
as part of our platform.

Our platform provides your teams with an easier solution for processing 
your HTTP/S data, as all of your logs can be sent directly to Logit.io for 
further processing, parsing & analysis.

Logit.io's hosted ELK (Elasticsearch, Logstash, & Kibana) solution allows 
you to get the best out your HTTP/S log data by providing your developers 
with complete visibility of their web requests & tail events in real-time.

If you need any more help with migrating your HTTP/S logs to a single 
centralised log management platform our team is here to help. Feel free to 
get in contact with our support team by sending us a message via 
<IntercomButton text="via live chat" /> & we'll be happy to assist.
